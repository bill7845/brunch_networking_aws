{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "preprocessing.ipynb",
      "provenance": [],
      "mount_file_id": "1qSILmWCPcJ7FcVoRKGRiUar3xErNcHIa",
      "authorship_tag": "ABX9TyPjoouEXa9ppDPISnNED4bC",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/bill7845/brunch_networking_aws/blob/main/Notebook/preprocessing.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9gkc0Npt3xME"
      },
      "source": [
        "\"\"\"\n",
        "Colab에서 Konlpy 사용\n",
        "\"\"\"\n",
        "!apt-get update\n",
        "!apt-get install g++ openjdk-8-jdk \n",
        "!pip3 install konlpy\n",
        "\n",
        "!git clone https://github.com/SOMJANG/Mecab-ko-for-Google-Colab.git"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ycr97EIPR4oN"
      },
      "source": [
        "cd Mecab-ko-for-Google-Colab/"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h5xcTuE2R6-K"
      },
      "source": [
        "! bash install_mecab-ko_on_colab190912.sh"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_-B3U9nK7Izg"
      },
      "source": [
        "\"\"\"\n",
        "AWS Setting\n",
        "\"\"\"\n",
        "!pip install boto3\n",
        "!pip install awscli"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eez9DQwZfEeM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9b2faa45-ddbf-425a-df63-fd405355ad39"
      },
      "source": [
        "## library import\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import json\n",
        "import os\n",
        "import pickle\n",
        "import urllib.request\n",
        "import re\n",
        "from ast import literal_eval\n",
        "from tqdm.notebook import tqdm\n",
        "from google.oauth2 import service_account\n",
        "from google.cloud import storage\n",
        "\n",
        "import boto3\n",
        "import os\n",
        "import io\n",
        "\n",
        "from konlpy.tag import Okt\n",
        "from konlpy.tag import Mecab\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "from sklearn.linear_model import LogisticRegression"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/requests/__init__.py:91: RequestsDependencyWarning: urllib3 (1.26.6) or chardet (3.0.4) doesn't match a supported version!\n",
            "  RequestsDependencyWarning)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NsMoNIzb7OGM"
      },
      "source": [
        "\"\"\"\n",
        "aws auth setting\n",
        "\"\"\"\n",
        "!aws configure"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q4alr5s3-tX2"
      },
      "source": [
        "\"\"\"\n",
        "bigquery Authentication setting.\n",
        "\"\"\"\n",
        "\n",
        "bq_credential_path = '/content/drive/MyDrive/Colab code/brunch_project/code/gcp_access/brunch-networking-07958d4e3d41.json'\n",
        "credentials = service_account.Credentials.from_service_account_file(bq_credential_path)\n",
        "project_id = 'brunch-networking-303012'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mz2xCSEf_nD2"
      },
      "source": [
        "def get_data_from_bq(credentials=credentials, project_id=project_id, class_num=int):\n",
        "  \n",
        "  if class_num == None:\n",
        "    \n",
        "    query = \"SELECT * FROM `brunch-networking-303012.brunch_networking.ori_brunch_data`\"\n",
        "    df = pd.read_gbq(query=query, project_id=project_id, credentials=credentials, dialect='standard')\n",
        "    \n",
        "  elif class_num != None:\n",
        "    query = \"SELECT * FROM `brunch-networking-303012.brunch_networking.ori_brunch_data` where class_num = {class_num}\".format(class_num=class_num)\n",
        "    df = pd.read_gbq(query=query, project_id=project_id, credentials=credentials, dialect='standard')\n",
        "\n",
        "  df = df[~df['text'].isnull()] # delete empty text row\n",
        "\n",
        "  return df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T7_9h80n6L51"
      },
      "source": [
        "def s3_upload(bucket_name , bucket_key, target_file_path):\n",
        "  \n",
        "  s3 = boto3.client('s3')\n",
        "  \n",
        "  s3.upload_file(\n",
        "      Filename = target_file_path,\n",
        "      Bucket = bucket_name,\n",
        "      Key = bucket_key\n",
        "  )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oW0LgnTHfPhr"
      },
      "source": [
        "def to_matrix_eachCategory(class_num, df):\n",
        "\n",
        "  mecab = Mecab()\n",
        "  \n",
        "  text = df['text']\n",
        "  text_plat = text.values.tolist()\n",
        "  \n",
        "  label = str(class_num)\n",
        "\n",
        "  prepared_data = []\n",
        "  tmp = None\n",
        "  for idx in range(len(text_plat)):\n",
        "      tmp = [i[0] for i in mecab.pos(text_plat[idx]) if ( ((i[1]==\"NNG\") or (i[1]==\"NNP\")) and(len(i[0])>1))] # 품사가 명사이면서, 길이가 2이상\n",
        "      prepared_data.append(\" \".join(tmp))\n",
        "\n",
        "  tfidf_vect = TfidfVectorizer(max_df=0.9)\n",
        "  tfidf_vect.fit(prepared_data)\n",
        "  tfidf_matrix = tfidf_vect.transform(prepared_data)\n",
        "\n",
        "  path_vect = '/content/drive/My Drive/Colab code/brunch_project/data/vect/each_vect/'\n",
        "  pickle.dump(tfidf_vect, open(os.path.join(path_vect,label+'tfidf_vect.pkl'),'wb'),protocol=4)\n",
        "\n",
        "  s3_upload(bucket_name='util-brunch-networking' , bucket_key='each_vect/' + label + \"tfidf_vect.pkl\", target_file_path=path_vect + label + 'tfidf_vect.pkl')\n",
        "\n",
        "  path_matrix = '/content/drive/My Drive/Colab code/brunch_project/data/vect/each_matrix/'\n",
        "  pickle.dump(tfidf_matrix, open(os.path.join(path_matrix,label+'tfidf_matrix.pkl'),'wb'),protocol=4)\n",
        "\n",
        "  s3_upload(bucket_name='util-brunch-networking' , bucket_key='each_matrix/' + label + \"tfidf_matrix.pkl\", target_file_path=path_matrix + label + 'tfidf_matrix.pkl')\n",
        "\n",
        "  return tfidf_matrix"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e7TelzXCBnQc"
      },
      "source": [
        "def keyword_vectorize(df):\n",
        "  \n",
        "  df = df[~pd.isnull(df['keyword'])]\n",
        "  df.loc[:,\"keyword\"] = df[\"keyword\"].apply(lambda x : literal_eval(str(x)))\n",
        "\n",
        "  df['keyword_literal'] = df['keyword'].apply(lambda x : (' ').join(x)) # keyword vector => [\"keyword1, keyword2, keyword3..\"]\n",
        "\n",
        "  keyword_count_vect = CountVectorizer() \n",
        "  keyword_mat = keyword_count_vect.fit_transform(df['keyword_literal']) # CountVectorizer로 벡터화\n",
        "\n",
        "\n",
        "  path_keyword_vect = '/content/drive/My Drive/Colab code/brunch_project/data/vect/keyword/'\n",
        "\n",
        "  pickle.dump(keyword_count_vect, open(os.path.join(path_keyword_vect,'keyword_count_vect.pkl'),'wb'),\n",
        "              protocol=4)\n",
        "  s3_upload(bucket_name='util-brunch-networking',\n",
        "            bucket_key='keyword_vect/' + \"keyword_count_vect.pkl\",\n",
        "            target_file_path=path_keyword_vect + 'keyword_count_vect.pkl')\n",
        "\n",
        "\n",
        "  pickle.dump(keyword_mat, open(os.path.join(path_keyword_vect,'keyword_mat.pkl'),'wb'),\n",
        "              protocol=4)\n",
        "  s3_upload(bucket_name='util-brunch-networking',\n",
        "            bucket_key='keyword_matrix/' + \"keyword_mat.pkl\",\n",
        "            target_file_path=path_keyword_vect + 'keyword_mat.pkl')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vt4frXctIUrD"
      },
      "source": [
        "## fixed range 0~17\n",
        "for i in range(0,18):\n",
        "  print(\"class \", i)\n",
        "  df = get_data_from_bq(class_num=i)\n",
        "  to_matrix_eachCategory(i,df)\n",
        "\n",
        "all_df = pd.read_csv(\"/content/drive/MyDrive/Colab code/brunch_project/data/basement/all_df.csv\") # load all_df.csv from google drive\n",
        "keyword_vectorize(df=all_df)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}